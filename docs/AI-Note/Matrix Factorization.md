# Matrix Factorization

## 1.推荐系统

推荐系统的研究从上世纪90年代初发展至今，目前有三大主流算法作为几乎全部的推荐算法的基石，它们就是基于内容的过滤算法（content-based filtering，简称CBF）、邻域算法（neighborhood methods）、隐语义模型（latent factor models，简称LFM），其中后两者统称为协同过滤算法（collaborative filtering，简CF）。

CBF通过给用户、物品定义显式的属性（通常会找所涉及的推荐领域的人类专家来定义）来描述他们的本质，然后为用户推荐与他们本质“门当户对”的物品；CF则是通过发动“群体的力量”，从其他用户、物品中学习到宝贵的信息，无需显式地定义属性：CF下的邻域算法着重于学习用户与用户、物品与物品之间的关系，为目标用户推荐与目标用户相似的用户所选择的物品（user-based）或者与目标用户所选择的物品相似的物品（item-based）；CF下的隐语义模型则是通过学习用户与用户、物品与物品之间的关系来自动获得用户、物品的隐属性（这里的“隐”指的是学习到的属性是不可解释的），相当于把用户-评分矩阵分解成用户隐属性矩阵和物品隐属性矩阵，然后通过用户隐属性向量u与物品隐属性向量i作点乘来获取到该用户对该物品的评分，以此为依据进行推荐。

<img src="https://s2.ax1x.com/2019/08/15/mArOeA.png" alt="" border="0" />

## 2.矩阵分解

### 2.1主要思想

 矩阵分解是构建隐语义模型的主要方法，即通过把整理、提取好的“用户—物品”评分矩阵进行分解，来得到一个用户隐向量矩阵和一个物品隐向量矩阵。假设现在有一个 M∗NM∗N 的矩阵，MM 代表用户数，NN 代表物品数，想将用户、物品分别训练出两个隐属性，即每个用户、每个物品都对应着一个二维向量，即得到了一个 M∗2M∗2 的用户隐向量矩阵和一个 N∗2N∗2 的矩阵，分解示意图如下所示：

<img src="https://s2.ax1x.com/2019/08/15/mAsmWT.png" alt="" border="0" />

### 2.2  矩阵分解方法

1. 三角分解法

2. QR分解法

3. 奇异值分解法

4. FM

5. 隐式反馈矩阵分解

6. 基于特征的矩阵分解

   

### 2.3矩阵分解步骤

<img src="https://s2.ax1x.com/2019/08/15/mAyYHs.png" alt="" border="0" />

### 3.实例

对于推荐系统来说存在两大场景即评分预测（rating prediction）与Top-N推荐（item recommendation，item ranking）。评分预测场景主要用于评价网站，比如用户给自己看过的电影评多少分（MovieLens），或者用户给自己看过的书籍评价多少分（Douban）。其中矩阵分解技术主要应用于该场景。Top-N推荐场景主要用于购物网站或者一般拿不到显式评分信息的网站，即通过用户的隐式反馈信息来给用户推荐一个可能感兴趣的列表以供其参考。

有如下R（5，4）的打分矩阵：（“-”表示用户没有打分）

其中打分矩阵R（n，m）是n行和m列，n表示user个数，m表示iten个数

<img src="https://s2.ax1x.com/2019/08/15/mA6AP0.png" alt="" border="0" />

那么，如何根据目前的矩阵R（5,4）如何对未打分的商品进行评分的预测（如何得到分值为0的用户的打分值）？

——矩阵分解的思想可以解决这个问题，其实这种思想可以看作是有监督的机器学习问题（回归问题）。

矩阵R可以近似表示为P与Q的乘积：R（n,m）≈ P(n,K)*Q(K,m)

矩阵分解的过程中，将原始的评分矩阵分解成两个矩阵和的乘积：

<img src="https://s2.ax1x.com/2019/08/15/mA6rJP.png" alt="" border="0" />

**1.首先令**

<img src="https://s2.ax1x.com/2019/08/15/mAcETA.png" alt="" border="0" />

**2.损失函数： 使用原始的评分矩阵与重新构建的评分矩阵之间的误差的平方作为损失函数。**

<img src="https://s2.ax1x.com/2019/08/15/mAcd6U.png" alt="" border="0" />

注：最终，需要求解所有的非“-”项的损失之和最小值

**3.使用梯度下降法获得修正的p和q分量，根据梯度方向更新变量：**

<img src="https://s2.ax1x.com/2019/08/15/mAcW6O.png" alt="" border="0" />

**然而，机器学习算法都喜欢加一个正则项，这里稍作修改，得到如下，beita 是正则参数**

<img src="https://s2.ax1x.com/2019/08/15/mAgK41.png" alt="" border="0" />

**相应的p,q矩阵各个元素的更新也换成了如下方式**

<img src="https://s2.ax1x.com/2019/08/15/mAg1gK.png" alt="" border="0" />

